experiment:
  dataset_filename: "news_category.csv"
  output_folder_name: "news_category"
  preprocessing:
    tokenization: "wordpunct"
    stemming: "wordnet"
    stopword_removal: true
    embedding_strategy: tfidf
    embedding_file: "word2vec-google-news-300"
  models:
    - model_name: svm
      params:
        kernels: [rbf, linear, poly]
        gammas: [auto]
        Cs: [1, 10, 100, 500]
        degrees: [2]
    - model_name: naive_bayes
      params: null
    - model_name: decision_tree
      params:
        criteria: [gini, entropy]
        splitters: [random, best]
        max_depths: [10,100,1000, 10000]
        min_samples_splits: [2,3,4]
        min_samples_leaves: [10, 100, 200]
  evaluation:
    #k_fold:
      #k: 5
      #focus_metric: accuracy
    validation_set:
      test_size: 0.2
      validation_split: 0.2
      focus_metric: accuracy
    metrics: [accuracy, precision, recall, f1score]
  output:
    output_filename: results.txt